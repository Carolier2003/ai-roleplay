<template>
  <div class="chat-input-bar">
    <!-- RAGåŠŸèƒ½å¼€å…³å·²ç§»é™¤ï¼Œé»˜è®¤å¼€å¯ -->

    <div class="input-container">
      <!-- è¯­éŸ³è½¬æ–‡å­—æŒ‰é’® (å·¦è¾¹) -->
      <n-button
        circle
        size="large"
        :type="voiceMode === 'voiceRecording' ? 'primary' : 'default'"
        class="voice-to-text-btn"
        @click="toggleRecording"
        :title="voiceMode === 'voiceRecording' ? 'ç‚¹å‡»åœæ­¢å½•éŸ³' : 'ç‚¹å‡»å¼€å§‹å½•éŸ³'"
      >
        <template #icon>
          <span v-if="voiceMode === 'text'" class="text-icon">T</span>
          <svg v-else-if="voiceMode === 'voiceRecording'" viewBox="0 0 24 24" width="20" height="20">
            <!-- å½•éŸ³ä¸­æ˜¾ç¤ºåœæ­¢å›¾æ ‡ -->
            <rect x="6" y="6" width="12" height="12" rx="2" fill="currentColor"/>
          </svg>
          <svg v-else viewBox="0 0 24 24" width="20" height="20">
            <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-2 15l-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z" fill="currentColor"/>
          </svg>
        </template>
      </n-button>

      <!-- éº¦å…‹é£æŒ‰é’® (åˆ‡æ¢è¯­éŸ³æ¶ˆæ¯æ¨¡å¼) -->
      <n-button
        circle
        size="large"
        :type="isVoiceMessageMode ? 'primary' : 'default'"
        class="microphone-btn"
        @click="toggleVoiceMessageMode"
        :title="isVoiceMessageMode ? 'åˆ‡æ¢åˆ°æ–‡å­—è¾“å…¥' : 'åˆ‡æ¢åˆ°è¯­éŸ³æ¶ˆæ¯'"
      >
        <template #icon>
          <svg v-if="!isVoiceMessageMode" viewBox="0 0 24 24" width="20" height="20">
            <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.48 6-3.3 6-6.72h-1.7z" fill="currentColor"/>
          </svg>
          <svg v-else viewBox="0 0 24 24" width="20" height="20">
            <path d="M3 17.25V21h3.75L17.81 9.94l-3.75-3.75L3 17.25zM20.71 7.04c.39-.39.39-1.02 0-1.41l-2.34-2.34c-.39-.39-1.02-.39-1.41 0l-1.83 1.83 3.75 3.75 1.83-1.83z" fill="currentColor"/>
          </svg>
        </template>
      </n-button>

      <!-- ç»Ÿä¸€çš„è¾“å…¥åŒºåŸŸ -->
      <div class="unified-input-area">
        <!-- è¯­éŸ³è½¬æ–‡å­—çŠ¶æ€æç¤º -->
        <div v-if="voiceMode === 'voiceTranscribing'" class="status-display">
          <n-spin size="small" />
          <span>æ­£åœ¨è½¬æ¢è¯­éŸ³...</span>
        </div>

        <!-- è¯­éŸ³æ³¢å½¢ -->
        <div v-else-if="voiceMode === 'voiceRecording'" class="status-display">
          <VoiceWave :recording="voiceMode === 'voiceRecording'" />
        </div>

        <!-- è¯­éŸ³é€šè¯çŠ¶æ€ -->
        <div v-else-if="isVoiceCallActive" class="status-display voice-call-status">
          <div class="voice-call-indicator">
            <div class="pulse-dot"></div>
            <span>è¯­éŸ³é€šè¯ä¸­...</span>
          </div>
        </div>

        <!-- è¯­éŸ³æ¶ˆæ¯æ¨¡å¼ï¼šé•¿æŒ‰å½•éŸ³æŒ‰é’® -->
        <div v-else-if="isVoiceMessageMode" class="voice-message-container">
          <n-button
            :type="isRecordingVoiceMessage ? 'primary' : 'default'"
            class="voice-message-btn"
            @mousedown="startVoiceMessageRecording"
            @mouseup="stopVoiceMessageRecording"
            @mouseleave="stopVoiceMessageRecording"
            @touchstart="startVoiceMessageRecording"
            @touchend="stopVoiceMessageRecording"
          >
            <template v-if="isRecordingVoiceMessage">
              <div class="recording-indicator">
                <div class="pulse-dot"></div>
                <span>æ¾å¼€å‘é€</span>
              </div>
            </template>
            <template v-else>
              <span>æŒ‰ä½è¯´è¯</span>
            </template>
          </n-button>
        </div>

        <!-- æ–‡æœ¬è¾“å…¥æ¡† -->
        <n-input
          v-else
          ref="inputRef"
          v-model:value="inputText"
          type="textarea"
          :placeholder="getPlaceholder()"
          :autosize="{ minRows: 1, maxRows: 3 }"
          :disabled="voiceMode === 'voiceTranscribing' || isVoiceCallActive"
          @keydown="handleKeydown"
          class="message-input"
        />
      </div>


      <!-- å‘é€/ç»ˆæ­¢æŒ‰é’® -->
      <n-button
        circle
        size="large"
        :type="sendButtonState.type === 'send' ? 'primary' : 'error'"
        :disabled="sendButtonState.disabled"
        :loading="sendButtonState.loading"
        @click="handleButtonClick"
        class="send-btn"
      >
        <template #icon>
          <!-- å‘é€å›¾æ ‡ -->
          <svg v-if="sendButtonState.icon === 'send'" viewBox="0 0 24 24" width="20" height="20">
            <path d="M2.01 21L23 12 2.01 3 2 10l15 2-15 2z" fill="currentColor"/>
          </svg>

          <!-- ç»ˆæ­¢å›¾æ ‡ -->
          <svg v-else-if="sendButtonState.icon === 'stop'" viewBox="0 0 24 24" width="20" height="20">
            <path d="M6 6h12v12H6z" fill="currentColor"/>
          </svg>
        </template>
      </n-button>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, nextTick, watch } from 'vue'
import { storeToRefs } from 'pinia'
import { NButton, NInput, NSpin, NTooltip, NSwitch, useMessage } from 'naive-ui'
import VoiceWave from './VoiceWave.vue'
import VoiceCallButton from './VoiceCallButton.vue'
import { useChatStore } from '@/stores/chat'
import { useAuthStore } from '@/stores/auth'
import { sendStreamMessage, updateVoiceDuration } from '@/api/chat'
import { SpeechRecognitionAPI, AudioConverter, SpeechRecognitionError, SpeechRecognitionUtils } from '@/api/speech'
import { speechConfig, getRecommendedRecordingConfig, isSpeechRecordingSupported } from '@/config/speech'
import type { SendMessageRequest, StreamResponse, UpdateVoiceDurationRequest } from '@/api/chat'
import { useTTSPlayer } from '@/composables/useTTSPlayer'
import { ttsState } from '@/services/ttsService'

interface Props {
  currentCharacterId?: number
}

interface Emits {
  send: [content: string]
}

const props = withDefaults(defineProps<Props>(), {
  currentCharacterId: undefined
})

const emit = defineEmits<Emits>()
const chatStore = useChatStore()
const authStore = useAuthStore()
const message = useMessage()

// RAGå¼€å…³çŠ¶æ€å·²ç§»é™¤ï¼Œç›´æ¥ä½¿ç”¨storeä¸­çš„çŠ¶æ€ï¼ˆé»˜è®¤å¼€å¯ï¼‰
// const { enableRag } = storeToRefs(chatStore)

// TTSæ’­æ”¾å™¨
const { addToQueue, stopPlaying, clearQueue } = useTTSPlayer()

const inputRef = ref<InstanceType<typeof NInput>>()
const inputText = ref('')
const mediaRecorder = ref<MediaRecorder | null>(null)
const audioChunks = ref<Blob[]>([])
const isSending = ref(false)
const isTerminated = ref(false)  // æ˜¯å¦ç»ˆæ­¢äº†æ¶ˆæ¯æ¥æ”¶
const currentAIMessageId = ref<string | null>(null)  // å½“å‰AIæ¶ˆæ¯ID
const isVoiceCallActive = ref(false)
const isVoiceMessageMode = ref(false)  // è¯­éŸ³æ¶ˆæ¯æ¨¡å¼
const isRecordingVoiceMessage = ref(false)  // æ˜¯å¦æ­£åœ¨å½•åˆ¶è¯­éŸ³æ¶ˆæ¯
const voiceMessageStartTime = ref(0)  // è¯­éŸ³æ¶ˆæ¯å¼€å§‹å½•åˆ¶æ—¶é—´
const voiceMessageDuration = ref(0)  // è¯­éŸ³æ¶ˆæ¯æ—¶é•¿
const pendingTextContent = ref('')  // TTSæ¨¡å¼ä¸‹æš‚å­˜çš„å®Œæ•´æ–‡å­—å†…å®¹

// å…¨å±€éŸ³é¢‘æ’­æ”¾æ§åˆ¶ - ç¡®ä¿åŒæ—¶åªæœ‰ä¸€æ¡è¯­éŸ³æ’­æ”¾
const currentPlayingAudio = ref<HTMLAudioElement | null>(null)  // å½“å‰æ’­æ”¾çš„éŸ³é¢‘å®ä¾‹


const voiceMode = computed(() => chatStore.voiceMode)
const canSend = computed(() => {
  return inputText.value.trim().length > 0 && voiceMode.value === 'text' && !isSending.value
})

// å‘é€æŒ‰é’®çŠ¶æ€è®¡ç®—
const sendButtonState = computed(() => {
  if (!isSending.value) {
    return {
      type: 'send',
      icon: 'send',
      disabled: !canSend.value,
      loading: voiceMode.value === 'voiceTranscribing'
    }
  }

  return {
    type: 'stop',
    icon: 'stop',
    disabled: false,
    loading: false
  }
})

const getPlaceholder = () => {
  switch (voiceMode.value) {
    case 'voiceRecording':
      return 'æ­£åœ¨å½•éŸ³...'
    case 'voiceTranscribing':
      return 'æ­£åœ¨è½¬æ¢è¯­éŸ³...'
    default:
      return 'è¾“å…¥æ¶ˆæ¯...'
  }
}

const handleKeydown = (e: KeyboardEvent) => {
  if (e.key === 'Enter' && !e.shiftKey) {
    e.preventDefault()
    handleButtonClick()
  }
}

// æŒ‰é’®ç‚¹å‡»å¤„ç†
const handleButtonClick = () => {
  switch (sendButtonState.value.type) {
    case 'send':
      handleSend()
      break
    case 'stop':
      handleStop()
      break
  }
}

// ç»ˆæ­¢æ¶ˆæ¯æ¥æ”¶å’Œæ’­æ”¾
const handleStop = () => {
  console.log('[ChatInputBar] ç»ˆæ­¢æ¶ˆæ¯æ¥æ”¶å’Œæ’­æ”¾')
  isTerminated.value = true

  // åœæ­¢TTSæ’­æ”¾
  stopTTSPlayback()

  // åœæ­¢AIæ¶ˆæ¯çš„æµå¼çŠ¶æ€ï¼ˆåœæ­¢å…‰æ ‡é—ªçƒï¼‰
  if (currentAIMessageId.value) {
    chatStore.updateMessage(currentAIMessageId.value, {
      streaming: false
    })
    console.log('[ChatInputBar] åœæ­¢AIæ¶ˆæ¯æµå¼çŠ¶æ€:', currentAIMessageId.value)
  }

  // é‡ç½®çŠ¶æ€
  isSending.value = false
  currentAIMessageId.value = null

  console.log('[ChatInputBar] æ¶ˆæ¯ç»ˆæ­¢å®Œæˆ')
}

// åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘ï¼ˆç¡®ä¿åŒæ—¶åªæœ‰ä¸€æ¡è¯­éŸ³æ’­æ”¾ï¼‰
const stopCurrentAudio = () => {
  if (currentPlayingAudio.value) {
    console.log('[ChatInputBar] åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘')
    currentPlayingAudio.value.pause()
    currentPlayingAudio.value.currentTime = 0
    currentPlayingAudio.value = null
  }
}

// åœæ­¢TTSæ’­æ”¾
const stopTTSPlayback = () => {
  // åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘
  stopCurrentAudio()

  // è·å–å½“å‰æ’­æ”¾çš„éŸ³é¢‘å…ƒç´ å¹¶åœæ­¢
  const audioElements = document.querySelectorAll('audio')
  audioElements.forEach(audio => {
    if (!audio.paused) {
      audio.pause()
      audio.currentTime = 0  // é‡ç½®æ’­æ”¾ä½ç½®
      console.log('[ChatInputBar] åœæ­¢éŸ³é¢‘æ’­æ”¾')
    }
  })
}


// åœæ­¢æ‰€æœ‰éŸ³é¢‘æ’­æ”¾
const stopAllAudio = () => {
  console.log('[ChatInputBar] åœæ­¢æ‰€æœ‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘')

  // åœæ­¢æ‰€æœ‰audioå…ƒç´ 
  const audioElements = document.querySelectorAll('audio')
  audioElements.forEach(audio => {
    if (!audio.paused) {
      audio.pause()
      console.log('[ChatInputBar] åœæ­¢éŸ³é¢‘å…ƒç´ æ’­æ”¾')
    }
  })

  // åœæ­¢TTSæ’­æ”¾å™¨
  try {
    if (stopPlaying) {
      stopPlaying()
      console.log('[ChatInputBar] åœæ­¢TTSæ’­æ”¾')
    }
    if (clearQueue) {
      clearQueue()
      console.log('[ChatInputBar] æ¸…ç©ºTTSé˜Ÿåˆ—')
    }
  } catch (error) {
    console.warn('[ChatInputBar] åœæ­¢TTSæ’­æ”¾å™¨å¤±è´¥:', error)
  }
}

const handleSend = async () => {
  if (!canSend.value) return
  
  const content = inputText.value.trim()
  if (!content) return
  
  // æ¸¸å®¢æ¨¡å¼å¯ä»¥ç›´æ¥èŠå¤©ï¼Œä¸éœ€è¦å¼ºåˆ¶ç™»å½•
  // æ³¨é‡Šæ‰ç™»å½•æ£€æŸ¥ï¼Œå…è®¸æ¸¸å®¢èŠå¤©
  
  // æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†è§’è‰²
  if (!chatStore.currentCharacterId) {
    message.warning('è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§’è‰²')
    return
  }
  
  try {
    // å‘é€æ–°æ¶ˆæ¯å‰ï¼Œå…ˆåœæ­¢ä¸Šä¸€æ¡æ­£åœ¨æ’­æ”¾çš„è¯­éŸ³
    stopAllAudio()

    isSending.value = true
    
    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©è®°å½•
    const userMessage = chatStore.addMessage({
      characterId: chatStore.currentCharacterId,
      content: content,
      isUser: true
    })
    
    // æ¸…ç©ºè¾“å…¥æ¡†
    inputText.value = ''
    
    // é‡æ–°èšç„¦è¾“å…¥æ¡†
    nextTick(() => {
      inputRef.value?.focus()
    })
    
    // åˆ›å»ºAIå›å¤æ¶ˆæ¯ï¼ˆæµå¼ï¼‰
    const aiMessage = chatStore.addMessage({
      characterId: chatStore.currentCharacterId,
      content: '',
      isUser: false,
      streaming: true
    })
    
    // ä¿å­˜å½“å‰AIæ¶ˆæ¯IDï¼Œç”¨äºç»ˆæ­¢æ§åˆ¶
    currentAIMessageId.value = aiMessage.id
    isTerminated.value = false  // é‡ç½®ç»ˆæ­¢çŠ¶æ€
    pendingTextContent.value = ''  // é‡ç½®æš‚å­˜çš„æ–‡å­—å†…å®¹

    // å‡†å¤‡å‘é€è¯·æ±‚ - åŒ¹é…åç«¯ ChatRequest å­—æ®µ
    // æ ¹æ®å½“å‰è¾“å…¥æ¨¡å¼å†³å®šæ˜¯å¦å¯ç”¨TTSï¼šæ–‡å­—æ¨¡å¼ä¸å¯ç”¨ï¼Œè¯­éŸ³æ¶ˆæ¯æ¨¡å¼å¯ç”¨
    const enableTtsForThisMessage = isVoiceMessageMode.value

    const requestData: SendMessageRequest = {
      characterId: chatStore.currentCharacterId,
      message: content,  // âœ… ä½¿ç”¨ message å­—æ®µåŒ¹é…åç«¯
      enableTts: enableTtsForThisMessage,   // âœ… æ ¹æ®è¾“å…¥æ¨¡å¼å†³å®šæ˜¯å¦å¯ç”¨TTS
      enableRag: chatStore.enableRag,  // âœ… ä¼ é€’RAGå¼€å…³çŠ¶æ€
      languageType: "Chinese"  // âœ… è®¾ç½®è¯­è¨€ç±»å‹
      // âœ… ä¸éœ€è¦ä¼ é€’ userIdï¼Œåç«¯ä» JWT token ä¸­è‡ªåŠ¨è·å–
    }
    
    console.log('[ChatInputBar] å‘é€æ¶ˆæ¯åˆ°åç«¯:', requestData)
    
    // å‘é€æµå¼è¯·æ±‚
    await sendStreamMessage(
      requestData,
      // onMessage - å¤„ç†æµå¼æ•°æ®
      (chunk: StreamResponse) => {
        console.log('[ChatInputBar] æ”¶åˆ°æµå¼æ•°æ®:', chunk)
        
        // å¦‚æœç»ˆæ­¢äº†ï¼Œå¿½ç•¥æ¶ˆæ¯å’ŒTTSäº‹ä»¶
        if (isTerminated.value && (chunk.type === 'message' || chunk.type === 'tts')) {
          console.log('[ChatInputBar] å·²ç»ˆæ­¢ï¼Œå¿½ç•¥äº‹ä»¶:', chunk.type)
          return
        }

        if (chunk.type === 'message' && chunk.content) {
          // æ ¹æ®æ˜¯å¦å¯ç”¨TTSæ¥å†³å®šå¤„ç†æ–¹å¼
          if (enableTtsForThisMessage) {
            // TTSæ¨¡å¼ï¼šæš‚å­˜æ–‡å­—å†…å®¹ï¼Œç­‰è¯­éŸ³ä¸‹è½½å®Œæˆåå†æ˜¾ç¤º
            pendingTextContent.value += chunk.content

            // æ˜¾ç¤º"æ­£åœ¨ç”Ÿæˆè¯­éŸ³..."çš„æç¤º
            chatStore.updateMessage(aiMessage.id, {
              content: 'ğŸµ æ­£åœ¨ç”Ÿæˆè¯­éŸ³...',
              isVoiceMessage: true
            })
            
            console.log('[ChatInputBar] TTSæ¨¡å¼ï¼šæš‚å­˜æ–‡å­—å†…å®¹ï¼Œç­‰å¾…è¯­éŸ³ç”Ÿæˆ:', {
              messageId: aiMessage.id,
              chunkContent: chunk.content,
              totalPendingLength: pendingTextContent.value.length
            })
          } else {
            // âœ…ä¼˜åŒ– è‡ªåŠ¨æ»šåŠ¨ - ä½¿ç”¨appendToStreamæ–¹æ³•ï¼Œæ¯æ®µå†…å®¹éƒ½ä¼šè§¦å‘æ»šåŠ¨
            chatStore.appendToStream(aiMessage.id, chunk.content)
            
            console.log('[ChatInputBar] æ–‡å­—æ¨¡å¼ï¼šæµå¼æ›´æ–°æ¶ˆæ¯å†…å®¹:', {
              messageId: aiMessage.id,
              newChunk: chunk.content,
              totalLength: (chatStore.messageList.find(m => m.id === aiMessage.id)?.content || '').length
            })
          }
        } else if (chunk.type === 'error') {
          console.error('[ChatInputBar] æµå¼å“åº”é”™è¯¯:', chunk.error)
          
          // æ£€æŸ¥æ˜¯å¦ä¸ºæ¸¸å®¢èŠå¤©é™åˆ¶é”™è¯¯
          if (chunk.error && chunk.error.includes('æ¸¸å®¢æ¨¡å¼æ¯æ—¥æœ€å¤šå¯èŠå¤©5æ¬¡')) {
            console.log('[ChatInputBar] æ¸¸å®¢èŠå¤©æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œç›´æ¥å¼¹å‡ºç™»å½•å¼¹çª—')
            // ç›´æ¥å¼¹å‡ºç™»å½•å¼¹çª—ï¼Œä¸æ˜¾ç¤ºä»»ä½•æç¤ºä¿¡æ¯
            authStore.showLoginModal()
          } else {
            message.error(chunk.error || 'æ¶ˆæ¯å‘é€å¤±è´¥')
          }
          
          // ç§»é™¤å¤±è´¥çš„AIæ¶ˆæ¯
          chatStore.removeMessage(aiMessage.id)
        } else if (chunk.type === 'tts') {
          console.log('[ChatInputBar] æ”¶åˆ°TTSäº‹ä»¶:', chunk)
          
          // å¤„ç†TTSéŸ³é¢‘æ’­æ”¾
          if (chunk.success && chunk.audioUrl) {
            console.log('[ChatInputBar] æ”¶åˆ°TTSéŸ³é¢‘URL:', chunk.audioUrl)
            
            // ä¿å­˜éŸ³é¢‘URLåˆ°æ¶ˆæ¯ä¸­ï¼Œä¾›åç»­ç‚¹å‡»æ’­æ”¾
            chatStore.updateMessage(aiMessage.id, {
              audioUrl: chunk.audioUrl,
              voice: chunk.voice,
              languageType: chunk.languageType,
              isVoiceMessage: isVoiceMessageMode.value
            })

            // ä¸‹è½½éŸ³é¢‘å¹¶æ’­æ”¾
            fetch(chunk.audioUrl)
              .then(response => response.blob())
              .then(audioBlob => {
                console.log('[ChatInputBar] TTSéŸ³é¢‘ä¸‹è½½æˆåŠŸï¼Œç°åœ¨åŒæ—¶æ˜¾ç¤ºæ–‡å­—å’Œæ’­æ”¾è¯­éŸ³')

                // ğŸ¯ å…³é”®æ”¹è¿›ï¼šTTSä¸‹è½½å®Œæˆåï¼ŒåŒæ—¶æ˜¾ç¤ºå®Œæ•´æ–‡å­—å†…å®¹
                if (enableTtsForThisMessage && pendingTextContent.value) {
                  console.log('[ChatInputBar] æ˜¾ç¤ºæš‚å­˜çš„å®Œæ•´æ–‡å­—å†…å®¹:', {
                    messageId: aiMessage.id,
                    textLength: pendingTextContent.value.length,
                    textPreview: pendingTextContent.value.substring(0, 50) + '...'
                  })

                  // æ›´æ–°æ¶ˆæ¯ï¼šæ˜¾ç¤ºå®Œæ•´æ–‡å­—å†…å®¹ï¼Œå¹¶æ ‡è®°ä¸ºè¯­éŸ³æ¶ˆæ¯
                  chatStore.updateMessage(aiMessage.id, {
                    content: pendingTextContent.value,
                    isVoiceMessage: true,
                    streaming: false  // ç¡®ä¿åœæ­¢æµå¼çŠ¶æ€ï¼Œå…‰æ ‡ä½äºæ–‡å­—æœ«å°¾
                  })

                  // æ¸…ç©ºæš‚å­˜çš„æ–‡å­—å†…å®¹
                  pendingTextContent.value = ''
                }

                // ğŸ¯ å…³é”®æ”¹è¿›ï¼šæ’­æ”¾æ–°éŸ³é¢‘å‰å…ˆåœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘
                stopCurrentAudio()
                
                // åˆ›å»ºä¸€ä¸ªç®€å•çš„æ’­æ”¾å™¨æ¥æ’­æ”¾éŸ³é¢‘
                const audioUrl = URL.createObjectURL(audioBlob)
                const audio = new Audio(audioUrl)
                audio.volume = 1.0
                
                // è®¾ç½®ä¸ºå½“å‰æ’­æ”¾çš„éŸ³é¢‘
                currentPlayingAudio.value = audio

                // ç›‘å¬éŸ³é¢‘å…ƒæ•°æ®è·å–æ—¶é•¿
                audio.addEventListener('loadedmetadata', () => {
                  const duration = Math.round(audio.duration) || 1
                  console.log('[ChatInputBar] TTSè¯­éŸ³æ—¶é•¿:', duration, 'ç§’')

                  // æ›´æ–°è¯­éŸ³æ—¶é•¿ä¿¡æ¯
                  chatStore.updateMessage(aiMessage.id, {
                    voiceDuration: duration
                  })
                })
                
                // ç›‘å¬éŸ³é¢‘æ’­æ”¾ç»“æŸï¼Œæ¸…ç†çŠ¶æ€
                audio.addEventListener('ended', () => {
                  console.log('[ChatInputBar] TTSéŸ³é¢‘æ’­æ”¾å®Œæˆ')
                  if (currentPlayingAudio.value === audio) {
                    currentPlayingAudio.value = null
                  }
                  URL.revokeObjectURL(audioUrl)
                })

                // ç›‘å¬éŸ³é¢‘æ’­æ”¾é”™è¯¯ï¼Œæ¸…ç†çŠ¶æ€
                audio.addEventListener('error', () => {
                  console.error('[ChatInputBar] TTSéŸ³é¢‘æ’­æ”¾å‡ºé”™')
                  if (currentPlayingAudio.value === audio) {
                    currentPlayingAudio.value = null
                  }
                  URL.revokeObjectURL(audioUrl)
                })

                return audio.play().then(() => {
                  console.log('[ChatInputBar] TTSéŸ³é¢‘å¼€å§‹æ’­æ”¾')
                })
              })
              .catch(error => {
                console.error('[ChatInputBar] TTSéŸ³é¢‘æ’­æ”¾å¤±è´¥:', error)
                message.warning('è¯­éŸ³æ’­æ”¾å¤±è´¥')

                // å¦‚æœéŸ³é¢‘æ’­æ”¾å¤±è´¥ï¼Œä»ç„¶è¦æ˜¾ç¤ºæ–‡å­—å†…å®¹
                if (enableTtsForThisMessage && pendingTextContent.value) {
                  console.log('[ChatInputBar] éŸ³é¢‘æ’­æ”¾å¤±è´¥ï¼Œä½†ä»æ˜¾ç¤ºæ–‡å­—å†…å®¹')
                  chatStore.updateMessage(aiMessage.id, {
                    content: pendingTextContent.value,
                    streaming: false
                  })
                  pendingTextContent.value = ''
                }
              })
          } else {
            console.warn('[ChatInputBar] TTSåˆæˆå¤±è´¥:', chunk.error)
            if (chunk.error) {
              message.warning(`è¯­éŸ³åˆæˆå¤±è´¥: ${chunk.error}`)
            }

            // TTSåˆæˆå¤±è´¥æ—¶ï¼Œæ˜¾ç¤ºæ–‡å­—å†…å®¹ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
            if (enableTtsForThisMessage && pendingTextContent.value) {
              console.log('[ChatInputBar] TTSåˆæˆå¤±è´¥ï¼Œæ˜¾ç¤ºæ–‡å­—å†…å®¹ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ')
              chatStore.updateMessage(aiMessage.id, {
                content: pendingTextContent.value,
                streaming: false
              })
              pendingTextContent.value = ''
            }
          }
        } else if (chunk.type === 'end') {
          console.log('[ChatInputBar] æ”¶åˆ°ç»“æŸä¿¡å·')
          // åœæ­¢æµå¼çŠ¶æ€
          chatStore.updateMessage(aiMessage.id, {
            streaming: false
          })
        }
      },
      // onError - å¤„ç†é”™è¯¯
      (error: Error) => {
        console.error('[ChatInputBar] æ¶ˆæ¯å‘é€å¤±è´¥:', error)
        message.error('æ¶ˆæ¯å‘é€å¤±è´¥: ' + error.message)
        
        // ç§»é™¤å¤±è´¥çš„AIæ¶ˆæ¯
        chatStore.removeMessage(aiMessage.id)
      },
      // onComplete - å®Œæˆå›è°ƒ
      () => {
        console.log('[ChatInputBar] æ¶ˆæ¯å‘é€å®Œæˆ')
        
        // å¦‚æœè¿˜æœ‰æš‚å­˜çš„æ–‡å­—å†…å®¹æœªæ˜¾ç¤ºï¼ˆæ¯”å¦‚æ²¡æœ‰TTSçš„æƒ…å†µï¼‰ï¼Œç¡®ä¿æ˜¾ç¤ºå‡ºæ¥
        if (pendingTextContent.value) {
          console.log('[ChatInputBar] å®Œæˆæ—¶å‘ç°æœªæ˜¾ç¤ºçš„æ–‡å­—å†…å®¹ï¼Œç«‹å³æ˜¾ç¤º')
          chatStore.updateMessage(aiMessage.id, {
            content: pendingTextContent.value,
            streaming: false
          })
          pendingTextContent.value = ''
        }

        // ç¡®ä¿åœæ­¢æµå¼çŠ¶æ€
        chatStore.updateMessage(aiMessage.id, {
          streaming: false
        })
        
        // é‡ç½®ç»ˆæ­¢çŠ¶æ€
        isTerminated.value = false
        currentAIMessageId.value = null

        // æ»šåŠ¨åˆ°åº•éƒ¨
        nextTick(() => {
          const chatContainer = document.querySelector('.chat-messages')
          if (chatContainer) {
            chatContainer.scrollTop = chatContainer.scrollHeight
          }
        })
      }
    )
    
  } catch (error) {
    console.error('[ChatInputBar] å‘é€æ¶ˆæ¯å¼‚å¸¸:', error)
    message.error('æ¶ˆæ¯å‘é€å¤±è´¥')
  } finally {
    isSending.value = false
    // ç¡®ä¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿé‡ç½®ç»ˆæ­¢çŠ¶æ€å’Œæš‚å­˜å†…å®¹
    if (currentAIMessageId.value) {
      isTerminated.value = false
      currentAIMessageId.value = null
    }
    pendingTextContent.value = ''  // æ¸…ç†æš‚å­˜çš„æ–‡å­—å†…å®¹
  }
}

// === è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½ï¼ˆç‚¹å‡»åˆ‡æ¢å½•éŸ³ï¼‰ ===
const toggleRecording = async () => {
  if (voiceMode.value === 'voiceRecording') {
    // å¦‚æœæ­£åœ¨å½•éŸ³ï¼Œåœæ­¢å½•éŸ³
    await stopRecording()
  } else {
    // å¦‚æœæ²¡æœ‰å½•éŸ³ï¼Œå¼€å§‹å½•éŸ³
    await startRecording()
  }
}

const startRecording = async () => {
  try {
    // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
    if (!isSpeechRecordingSupported()) {
      message.error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³å½•åˆ¶åŠŸèƒ½')
      return
    }
    
    // è·å–æ¨èçš„å½•éŸ³é…ç½®
    const recordingConfig = getRecommendedRecordingConfig()
    
    console.log('[ChatInputBar] å¼€å§‹å½•éŸ³ï¼Œé…ç½®:', recordingConfig)
    
    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        sampleRate: speechConfig.recognition.sampleRate,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    })
    
    mediaRecorder.value = new MediaRecorder(stream, {
      mimeType: recordingConfig.mimeType,
      audioBitsPerSecond: recordingConfig.audioBitsPerSecond
    })
    
    audioChunks.value = []
    
    mediaRecorder.value.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.value.push(event.data)
      }
    }
    
    mediaRecorder.value.onstop = async () => {
      const audioBlob = new Blob(audioChunks.value, { type: recordingConfig.mimeType })
      
      // æ£€æŸ¥å½•éŸ³æ—¶é•¿
      if (audioBlob.size < 1000) { // å°äº1KBè®¤ä¸ºå½•éŸ³å¤ªçŸ­
        message.warning('å½•éŸ³æ—¶é—´å¤ªçŸ­ï¼Œè¯·é‡æ–°å½•åˆ¶')
        chatStore.setVoiceMode('text')
        return
      }
      
      console.log('[ChatInputBar] å½•éŸ³å®Œæˆï¼Œæ ¼å¼:', recordingConfig.format, 'å¤§å°:', audioBlob.size, 'bytes')
      
      await processAudioBlob(audioBlob)
      
      // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
      stream.getTracks().forEach(track => track.stop())
    }
    
    mediaRecorder.value.start()
    chatStore.setVoiceMode('voiceRecording')
    
    // éœ‡åŠ¨åé¦ˆï¼ˆå¦‚æœæ”¯æŒï¼‰
    if (speechConfig.ui.vibrationOnStart && navigator.vibrate) {
      navigator.vibrate(50)
    }
    
  } catch (error) {
    console.error('[ChatInputBar] å½•éŸ³å¯åŠ¨å¤±è´¥:', error)
    
    if (error instanceof Error) {
      if (error.name === 'NotAllowedError') {
        message.error('è¯·å…è®¸è®¿é—®éº¦å…‹é£æƒé™')
      } else if (error.name === 'NotFoundError') {
        message.error('æœªæ‰¾åˆ°å¯ç”¨çš„éº¦å…‹é£è®¾å¤‡')
      } else {
        message.error('å½•éŸ³å¯åŠ¨å¤±è´¥: ' + error.message)
      }
    } else {
      message.error('å½•éŸ³å¯åŠ¨å¤±è´¥ï¼Œè¯·é‡è¯•')
    }
    
    chatStore.setVoiceMode('text')
  }
}

const stopRecording = async () => {
  if (mediaRecorder.value && mediaRecorder.value.state === 'recording') {
    console.log('[ChatInputBar] åœæ­¢å½•éŸ³')
    mediaRecorder.value.stop()
    chatStore.setVoiceMode('voiceTranscribing')
    
    // éœ‡åŠ¨åé¦ˆï¼ˆå¦‚æœæ”¯æŒï¼‰
    if (speechConfig.ui.vibrationOnStop && navigator.vibrate) {
      navigator.vibrate(30)
    }
    
    console.log('[ChatInputBar] å½•éŸ³å·²åœæ­¢ï¼Œå¼€å§‹å¤„ç†éŸ³é¢‘')
  }
}

const processAudioBlob = async (audioBlob: Blob) => {
  try {
    console.log('[ChatInputBar] å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼ŒåŸå§‹æ ¼å¼:', audioBlob.type, 'å¤§å°:', audioBlob.size, 'bytes')
    
    // å°†éŸ³é¢‘è½¬æ¢ä¸ºWAVæ ¼å¼
    console.log('[ChatInputBar] å¼€å§‹è½¬æ¢éŸ³é¢‘ä¸ºWAVæ ¼å¼...')
    const wavBlob = await AudioConverter.toWav(audioBlob)
    console.log('[ChatInputBar] éŸ³é¢‘è½¬æ¢å®Œæˆï¼ŒWAVå¤§å°:', wavBlob.size, 'bytes')
    
    // è°ƒç”¨çœŸå®çš„è¯­éŸ³è¯†åˆ«APIï¼Œä½¿ç”¨è½¬æ¢åçš„WAVæ–‡ä»¶
    const response = await SpeechRecognitionAPI.recognizeAudio(wavBlob, {
      model: speechConfig.recognition.model,
      format: speechConfig.recognition.format, // 'wav'
      sampleRate: speechConfig.recognition.sampleRate,
      punctuationPredictionEnabled: speechConfig.recognition.punctuationPredictionEnabled,
      semanticPunctuationEnabled: speechConfig.recognition.semanticPunctuationEnabled,
      maxSentenceSilence: speechConfig.recognition.maxSentenceSilence,
      languageHints: speechConfig.recognition.languageHints
    })
    
    console.log('[ChatInputBar] è¯­éŸ³è¯†åˆ«æˆåŠŸ:', response)
    
    // ä½¿ç”¨å·¥å…·ç±»æå–æ–‡æœ¬
    const recognizedText = SpeechRecognitionUtils.extractTextFromResponse(response)
    console.log('[ChatInputBar] æå–çš„æ–‡æœ¬:', recognizedText)
    
    // éªŒè¯è¯†åˆ«ç»“æœæ˜¯å¦æœ‰æ•ˆ
    if (!SpeechRecognitionUtils.isValidRecognitionResult(recognizedText)) {
      console.warn('[ChatInputBar] è¯†åˆ«ç»“æœæ— æ•ˆæˆ–ä¸ºç©º:', recognizedText)
      message.warning('æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³å†…å®¹ï¼Œè¯·é‡æ–°å½•åˆ¶')
      chatStore.setVoiceMode('text')
      return
    }
    
    // å°†è½¬æ¢çš„æ–‡å­—å¡«å…¥è¾“å…¥æ¡†
    inputText.value = recognizedText
    chatStore.setVoiceMode('text')
    
    // æ˜¾ç¤ºæˆåŠŸæç¤ºï¼ˆå¦‚æœé…ç½®å¯ç”¨ï¼‰
    if (speechConfig.ui.showConfidence) {
      if (response.confidence !== undefined && response.confidence !== null && !isNaN(response.confidence)) {
        message.success(`è¯­éŸ³è¯†åˆ«æˆåŠŸï¼Œç½®ä¿¡åº¦: ${Math.round(response.confidence * 100)}%`)
      } else {
        message.success('è¯­éŸ³è¯†åˆ«æˆåŠŸ')
      }
    }
    
    // TæŒ‰é’®çš„è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½ï¼šä¸è‡ªåŠ¨å‘é€ï¼Œè®©ç”¨æˆ·ç¼–è¾‘åå†å‘é€
    // èšç„¦è¾“å…¥æ¡†ï¼Œæ–¹ä¾¿ç”¨æˆ·ç¼–è¾‘
    await nextTick()
    inputRef.value?.focus()
    
    // æ˜¾ç¤ºæç¤ºä¿¡æ¯
    message.success('è¯­éŸ³è¯†åˆ«å®Œæˆï¼Œè¯·æ£€æŸ¥æ–‡å­—åå‘é€')
    
  } catch (error) {
    console.error('[ChatInputBar] è¯­éŸ³è½¬æ–‡å­—å¤±è´¥:', error)
    
    // å¤„ç†ä¸åŒç±»å‹çš„é”™è¯¯
    if (error instanceof SpeechRecognitionError) {
      message.error(`è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error.message}`)
    } else if (error instanceof Error) {
      // æ£€æŸ¥æ˜¯å¦æ˜¯éŸ³é¢‘è½¬æ¢é”™è¯¯
      if (error.message.includes('decodeAudioData') || error.message.includes('AudioContext')) {
        message.error('éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œè¯·é‡æ–°å½•åˆ¶')
      } else {
        message.error(`è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error.message}`)
      }
    } else {
      message.error('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•')
    }
    
    chatStore.setVoiceMode('text')
  }
}

// === è¯­éŸ³æ¶ˆæ¯åŠŸèƒ½ ===
const toggleVoiceMessageMode = () => {
  console.log('[ChatInputBar] åˆ‡æ¢è¯­éŸ³æ¶ˆæ¯æ¨¡å¼:', !isVoiceMessageMode.value)
  isVoiceMessageMode.value = !isVoiceMessageMode.value
  
  // å¦‚æœåˆ‡æ¢åˆ°æ–‡å­—æ¨¡å¼ï¼Œæ¸…ç†è¯­éŸ³æ¶ˆæ¯çŠ¶æ€
  if (!isVoiceMessageMode.value) {
    isRecordingVoiceMessage.value = false
  }
}

const startVoiceMessageRecording = async () => {
  if (!props.currentCharacterId) {
    message.warning('è¯·å…ˆé€‰æ‹©è§’è‰²')
    return
  }
  
  try {
    console.log('[ChatInputBar] å¼€å§‹å½•åˆ¶è¯­éŸ³æ¶ˆæ¯')
    
    // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
    if (!isSpeechRecordingSupported()) {
      message.error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³å½•åˆ¶åŠŸèƒ½')
      return
    }
    
    // è·å–æ¨èçš„å½•éŸ³é…ç½®
    const recordingConfig = getRecommendedRecordingConfig()
    
    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        sampleRate: speechConfig.recognition.sampleRate,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    })
    
    mediaRecorder.value = new MediaRecorder(stream, {
      mimeType: recordingConfig.mimeType,
      audioBitsPerSecond: recordingConfig.audioBitsPerSecond
    })
    
    audioChunks.value = []
    
    mediaRecorder.value.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.value.push(event.data)
      }
    }
    
    mediaRecorder.value.onstop = async () => {
      const audioBlob = new Blob(audioChunks.value, { type: recordingConfig.mimeType })
      
      // æ£€æŸ¥å½•éŸ³æ—¶é•¿
      if (audioBlob.size < 1000) { // å°äº1KBè®¤ä¸ºå½•éŸ³å¤ªçŸ­
        message.warning('å½•éŸ³æ—¶é—´å¤ªçŸ­ï¼Œè¯·é‡æ–°å½•åˆ¶')
        return
      }
      
      console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯å½•åˆ¶å®Œæˆï¼Œå¼€å§‹å‘é€')
      await processVoiceMessage(audioBlob)
      
      // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
      stream.getTracks().forEach(track => track.stop())
    }
    
    mediaRecorder.value.start()
    isRecordingVoiceMessage.value = true
    voiceMessageStartTime.value = Date.now()  // è®°å½•å¼€å§‹æ—¶é—´
    
    // éœ‡åŠ¨åé¦ˆï¼ˆå¦‚æœæ”¯æŒï¼‰
    if (speechConfig.ui.vibrationOnStart && navigator.vibrate) {
      navigator.vibrate(50)
    }
    
  } catch (error) {
    console.error('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯å½•åˆ¶å¯åŠ¨å¤±è´¥:', error)
    
    if (error instanceof Error) {
      if (error.name === 'NotAllowedError') {
        message.error('è¯·å…è®¸è®¿é—®éº¦å…‹é£æƒé™')
      } else if (error.name === 'NotFoundError') {
        message.error('æœªæ‰¾åˆ°å¯ç”¨çš„éº¦å…‹é£è®¾å¤‡')
      } else {
        message.error('å½•éŸ³å¯åŠ¨å¤±è´¥: ' + error.message)
      }
    } else {
      message.error('å½•éŸ³å¯åŠ¨å¤±è´¥ï¼Œè¯·é‡è¯•')
    }
    
    isRecordingVoiceMessage.value = false
  }
}

const stopVoiceMessageRecording = () => {
  if (mediaRecorder.value && mediaRecorder.value.state === 'recording') {
    console.log('[ChatInputBar] åœæ­¢å½•åˆ¶è¯­éŸ³æ¶ˆæ¯')
    
    // è®¡ç®—å½•éŸ³æ—¶é•¿
    const endTime = Date.now()
    const duration = Math.round((endTime - voiceMessageStartTime.value) / 1000)
    voiceMessageDuration.value = Math.max(1, duration)  // æœ€å°‘1ç§’
    
    console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯å½•åˆ¶æ—¶é•¿:', voiceMessageDuration.value, 'ç§’')
    
    mediaRecorder.value.stop()
    isRecordingVoiceMessage.value = false
    
    // éœ‡åŠ¨åé¦ˆï¼ˆå¦‚æœæ”¯æŒï¼‰
    if (speechConfig.ui.vibrationOnStop && navigator.vibrate) {
      navigator.vibrate(30)
    }
  }
}

const processVoiceMessage = async (audioBlob: Blob) => {
  try {
    console.log('[ChatInputBar] å¼€å§‹å¤„ç†è¯­éŸ³æ¶ˆæ¯')
    
    // å‘é€æ–°è¯­éŸ³æ¶ˆæ¯å‰ï¼Œå…ˆåœæ­¢ä¸Šä¸€æ¡æ­£åœ¨æ’­æ”¾çš„è¯­éŸ³
    stopAllAudio()

    // å°†éŸ³é¢‘è½¬æ¢ä¸ºWAVæ ¼å¼
    const wavBlob = await AudioConverter.toWav(audioBlob)
    console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯è½¬æ¢å®Œæˆï¼ŒWAVå¤§å°:', wavBlob.size, 'bytes')
    
    // å…ˆè¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œè·å–æ–‡æœ¬å†…å®¹
    const response = await SpeechRecognitionAPI.recognizeAudio(wavBlob, {
      model: speechConfig.recognition.model,
      format: speechConfig.recognition.format,
      sampleRate: speechConfig.recognition.sampleRate,
      punctuationPredictionEnabled: speechConfig.recognition.punctuationPredictionEnabled,
      semanticPunctuationEnabled: speechConfig.recognition.semanticPunctuationEnabled,
      maxSentenceSilence: speechConfig.recognition.maxSentenceSilence,
      languageHints: speechConfig.recognition.languageHints
    })
    
    console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯è¯†åˆ«æˆåŠŸ:', response)
    
    // ä½¿ç”¨å·¥å…·ç±»æå–æ–‡æœ¬
    const recognizedText = SpeechRecognitionUtils.extractTextFromResponse(response)
    console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯æå–çš„æ–‡æœ¬:', recognizedText)
    
    // éªŒè¯è¯†åˆ«ç»“æœæ˜¯å¦æœ‰æ•ˆ
    if (!SpeechRecognitionUtils.isValidRecognitionResult(recognizedText)) {
      console.warn('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯è¯†åˆ«ç»“æœæ— æ•ˆæˆ–ä¸ºç©º:', recognizedText)
      message.warning('æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³å†…å®¹ï¼Œè¯·é‡æ–°å½•åˆ¶')
      return
    }
    
    // å‘é€è¯­éŸ³æ¶ˆæ¯ï¼šæ˜¾ç¤ºä¸ºè¯­éŸ³ä¿¡æ¯æ ‡è¯†ï¼ŒåŒ…å«æ—¶é•¿
    const voiceMessageContent = `ğŸµ ${voiceMessageDuration.value}"`
    inputText.value = voiceMessageContent
    
    // æ·»åŠ ç”¨æˆ·è¯­éŸ³æ¶ˆæ¯åˆ°èŠå¤©è®°å½•
    const userMessage = chatStore.addMessage({
      characterId: chatStore.currentCharacterId,
      content: voiceMessageContent,
      isUser: true,
      isVoiceMessage: true,
      voiceDuration: voiceMessageDuration.value
    })
    
    // è°ƒç”¨åç«¯APIæ›´æ–°è¯­éŸ³æ—¶é•¿
    try {
      const updateRequest: UpdateVoiceDurationRequest = {
        messageContent: voiceMessageContent,
        voiceDuration: voiceMessageDuration.value,
        characterId: chatStore.currentCharacterId
      }
      
      console.log('[ChatInputBar] æ›´æ–°è¯­éŸ³æ—¶é•¿åˆ°åç«¯:', updateRequest)
      const updateResponse = await updateVoiceDuration(updateRequest)
      
      if (updateResponse.success) {
        console.log('[ChatInputBar] è¯­éŸ³æ—¶é•¿æ›´æ–°æˆåŠŸ:', updateResponse)
      } else {
        console.warn('[ChatInputBar] è¯­éŸ³æ—¶é•¿æ›´æ–°å¤±è´¥:', updateResponse.message)
      }
    } catch (error) {
      console.error('[ChatInputBar] æ›´æ–°è¯­éŸ³æ—¶é•¿å¤±è´¥:', error)
      // ä¸å½±å“ä¸»æµç¨‹ï¼Œåªè®°å½•é”™è¯¯
    }
    
    // æ¸…ç©ºè¾“å…¥æ¡†
    inputText.value = ''
    
    // å®é™…å‘é€è¯†åˆ«çš„æ–‡æœ¬ç»™AIï¼ˆä½†ä¸æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼‰
    const requestData: SendMessageRequest = {
      characterId: chatStore.currentCharacterId,
      message: recognizedText,  // å‘é€å®é™…çš„æ–‡å­—å†…å®¹ç»™AI
      enableTts: true,  // è¯­éŸ³æ¶ˆæ¯æ¨¡å¼å§‹ç»ˆå¯ç”¨TTS
      enableRag: chatStore.enableRag,  // âœ… ä¼ é€’RAGå¼€å…³çŠ¶æ€
      languageType: "Chinese"
    }
    
    console.log('[ChatInputBar] å‘é€è¯­éŸ³æ¶ˆæ¯åˆ°åç«¯:', requestData)
    
    // åˆ›å»ºAIå›å¤æ¶ˆæ¯ï¼ˆæµå¼ï¼‰
    const aiMessage = chatStore.addMessage({
      characterId: chatStore.currentCharacterId,
      content: '',
      isUser: false,
      streaming: true
    })
    
    // ä¿å­˜å½“å‰AIæ¶ˆæ¯IDï¼Œç”¨äºç»ˆæ­¢æ§åˆ¶
    currentAIMessageId.value = aiMessage.id
    isTerminated.value = false  // é‡ç½®ç»ˆæ­¢çŠ¶æ€
    pendingTextContent.value = ''  // é‡ç½®æš‚å­˜çš„æ–‡å­—å†…å®¹

    // å‘é€æµå¼è¯·æ±‚
    await sendStreamMessage(
      requestData,
      // onMessage - å¤„ç†æµå¼æ•°æ®
      (chunk: StreamResponse) => {
        console.log('[ChatInputBar] æ”¶åˆ°è¯­éŸ³æ¶ˆæ¯æµå¼æ•°æ®:', chunk)
        
        // å¦‚æœç»ˆæ­¢äº†ï¼Œå¿½ç•¥æ¶ˆæ¯å’ŒTTSäº‹ä»¶
        if (isTerminated.value && (chunk.type === 'message' || chunk.type === 'tts')) {
          console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯å·²ç»ˆæ­¢ï¼Œå¿½ç•¥äº‹ä»¶:', chunk.type)
          return
        }

        if (chunk.type === 'message' && chunk.content) {
          // è¯­éŸ³æ¶ˆæ¯æ¨¡å¼ï¼šæš‚å­˜æ–‡å­—å†…å®¹ï¼Œç­‰è¯­éŸ³ä¸‹è½½å®Œæˆåå†æ˜¾ç¤º
          pendingTextContent.value += chunk.content

          // æ˜¾ç¤º"æ­£åœ¨ç”Ÿæˆè¯­éŸ³..."çš„æç¤º
          chatStore.updateMessage(aiMessage.id, {
            content: 'ğŸµ æ­£åœ¨ç”Ÿæˆè¯­éŸ³...',
            isVoiceMessage: true
          })

          console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯æ¨¡å¼ï¼šæš‚å­˜æ–‡å­—å†…å®¹:', {
            messageId: aiMessage.id,
            chunkContent: chunk.content,
            totalPendingLength: pendingTextContent.value.length
          })
        } else if (chunk.type === 'tts') {
          console.log('[ChatInputBar] æ”¶åˆ°è¯­éŸ³æ¶ˆæ¯TTSäº‹ä»¶:', chunk)
          
          // å¤„ç†TTSéŸ³é¢‘æ’­æ”¾
          if (chunk.success && chunk.audioUrl) {
            console.log('[ChatInputBar] æ”¶åˆ°è¯­éŸ³æ¶ˆæ¯TTSéŸ³é¢‘URL:', chunk.audioUrl)
            
            // ä¿å­˜éŸ³é¢‘URLåˆ°æ¶ˆæ¯ä¸­ï¼Œä¾›åç»­ç‚¹å‡»æ’­æ”¾
            chatStore.updateMessage(aiMessage.id, {
              audioUrl: chunk.audioUrl,
              voice: chunk.voice,
              languageType: chunk.languageType,
              isVoiceMessage: true
            })

            // ä¸‹è½½å¹¶æ’­æ”¾éŸ³é¢‘
            fetch(chunk.audioUrl)
              .then(response => response.blob())
              .then(audioBlob => {
                console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯TTSéŸ³é¢‘ä¸‹è½½æˆåŠŸï¼Œç°åœ¨åŒæ—¶æ˜¾ç¤ºæ–‡å­—å’Œæ’­æ”¾è¯­éŸ³')

                // ğŸ¯ å…³é”®æ”¹è¿›ï¼šTTSä¸‹è½½å®Œæˆåï¼ŒåŒæ—¶æ˜¾ç¤ºå®Œæ•´æ–‡å­—å†…å®¹
                if (pendingTextContent.value) {
                  console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯ï¼šæ˜¾ç¤ºæš‚å­˜çš„å®Œæ•´æ–‡å­—å†…å®¹:', {
                    messageId: aiMessage.id,
                    textLength: pendingTextContent.value.length,
                    textPreview: pendingTextContent.value.substring(0, 50) + '...'
                  })

                  // æ›´æ–°æ¶ˆæ¯ï¼šæ˜¾ç¤ºå®Œæ•´æ–‡å­—å†…å®¹ï¼Œå¹¶æ ‡è®°ä¸ºè¯­éŸ³æ¶ˆæ¯
                  chatStore.updateMessage(aiMessage.id, {
                    content: pendingTextContent.value,
                    isVoiceMessage: true,
                    streaming: false  // ç¡®ä¿åœæ­¢æµå¼çŠ¶æ€ï¼Œå…‰æ ‡ä½äºæ–‡å­—æœ«å°¾
                  })

                  // æ¸…ç©ºæš‚å­˜çš„æ–‡å­—å†…å®¹
                  pendingTextContent.value = ''
                }

                // ğŸ¯ å…³é”®æ”¹è¿›ï¼šæ’­æ”¾æ–°éŸ³é¢‘å‰å…ˆåœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘
                stopCurrentAudio()
                
                const audioUrl = URL.createObjectURL(audioBlob)
                const audio = new Audio(audioUrl)
                audio.volume = 1.0
                
                // è®¾ç½®ä¸ºå½“å‰æ’­æ”¾çš„éŸ³é¢‘
                currentPlayingAudio.value = audio

                // ç›‘å¬éŸ³é¢‘å…ƒæ•°æ®åŠ è½½ï¼Œè·å–æ—¶é•¿
                audio.addEventListener('loadedmetadata', () => {
                  const duration = Math.round(audio.duration) || 1
                  console.log('[ChatInputBar] AIè¯­éŸ³æ¶ˆæ¯æ—¶é•¿:', duration, 'ç§’')
                  
                  // æ›´æ–°è¯­éŸ³æ—¶é•¿ä¿¡æ¯
                  chatStore.updateMessage(aiMessage.id, {
                    voiceDuration: duration
                  })
                })
                
                // ç›‘å¬éŸ³é¢‘æ’­æ”¾ç»“æŸï¼Œæ¸…ç†çŠ¶æ€
                audio.addEventListener('ended', () => {
                  console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯TTSéŸ³é¢‘æ’­æ”¾å®Œæˆ')
                  if (currentPlayingAudio.value === audio) {
                    currentPlayingAudio.value = null
                  }
                  URL.revokeObjectURL(audioUrl)
                })

                // ç›‘å¬éŸ³é¢‘æ’­æ”¾é”™è¯¯ï¼Œæ¸…ç†çŠ¶æ€
                audio.addEventListener('error', () => {
                  console.error('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯TTSéŸ³é¢‘æ’­æ”¾å‡ºé”™')
                  if (currentPlayingAudio.value === audio) {
                    currentPlayingAudio.value = null
                  }
                  URL.revokeObjectURL(audioUrl)
                })

                return audio.play().then(() => {
                  console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯TTSéŸ³é¢‘å¼€å§‹æ’­æ”¾')
                })
              })
              .catch(error => {
                console.error('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯TTSéŸ³é¢‘æ’­æ”¾å¤±è´¥:', error)
                message.warning('è¯­éŸ³æ’­æ”¾å¤±è´¥')
              })
          }
        } else if (chunk.type === 'end') {
          console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯æµå¼å“åº”ç»“æŸ')
          chatStore.updateMessage(aiMessage.id, {
            streaming: false
          })
        }
      },
      // onError
      (error: Error) => {
        console.error('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯å‘é€å¤±è´¥:', error)
        message.error('è¯­éŸ³æ¶ˆæ¯å‘é€å¤±è´¥: ' + error.message)
        chatStore.removeMessage(aiMessage.id)
      },
      // onComplete
      () => {
        console.log('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯å‘é€å®Œæˆ')
        chatStore.updateMessage(aiMessage.id, {
          streaming: false
        })

        // é‡ç½®ç»ˆæ­¢çŠ¶æ€
        isTerminated.value = false
        currentAIMessageId.value = null
      }
    )
    
    message.success('è¯­éŸ³æ¶ˆæ¯å‘é€æˆåŠŸ')
    
  } catch (error) {
    console.error('[ChatInputBar] è¯­éŸ³æ¶ˆæ¯å¤„ç†å¤±è´¥:', error)
    
    // å¤„ç†ä¸åŒç±»å‹çš„é”™è¯¯
    if (error instanceof SpeechRecognitionError) {
      message.error(`è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error.message}`)
    } else if (error instanceof Error) {
      if (error.message.includes('decodeAudioData') || error.message.includes('AudioContext')) {
        message.error('éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œè¯·é‡æ–°å½•åˆ¶')
      } else {
        message.error(`è¯­éŸ³æ¶ˆæ¯å‘é€å¤±è´¥: ${error.message}`)
      }
    } else {
      message.error('è¯­éŸ³æ¶ˆæ¯å‘é€å¤±è´¥ï¼Œè¯·é‡è¯•')
    }
  }
}

</script>

<style scoped>
.chat-input-bar {
  max-width: 1200px;
  margin: 0 auto;
  width: 100%;
}

.input-container {
  display: flex;
  align-items: center;
  gap: 12px;
  padding: 12px 16px;
  background: white;
  border-radius: 24px;
  border: 1px solid var(--gray-200);
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
  transition: all 0.2s ease;
  min-height: 56px;
}

.input-container:hover {
  box-shadow: 0 6px 20px rgba(0, 0, 0, 0.12);
  border-color: var(--primary-300);
}

.input-container:focus-within {
  box-shadow: 0 6px 20px rgba(22, 119, 255, 0.15);
  border-color: var(--primary-500);
}

.voice-to-text-btn {
  flex-shrink: 0;
  width: 40px !important;
  height: 40px !important;
  transition: all 0.2s ease;
}

.voice-to-text-btn:active {
  transform: scale(0.95);
}

.text-icon {
  font-size: 18px;
  font-weight: bold;
  color: currentColor;
}

.microphone-btn {
  flex-shrink: 0;
  width: 40px !important;
  height: 40px !important;
  transition: all 0.2s ease;
}

.microphone-btn:active {
  transform: scale(0.95);
}

.microphone-btn.n-button--primary {
  animation: microphone-pulse 1.5s ease-in-out infinite;
}

.unified-input-area {
  flex: 1;
  min-height: 40px;
  display: flex;
  align-items: center;
  background: var(--gray-50);
  border-radius: 20px;
  padding: 8px 16px;
  margin: 0 4px;
}

.status-display {
  width: 100%;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 8px;
  font-size: 14px;
  color: var(--primary-color);
}

.voice-call-status {
  color: var(--success-color);
}

.voice-call-indicator {
  display: flex;
  align-items: center;
  gap: 8px;
}

.pulse-dot {
  width: 8px;
  height: 8px;
  background: var(--success-color);
  border-radius: 50%;
  animation: pulse-dot 1.5s ease-in-out infinite;
}

.voice-message-container {
  width: 100%;
  display: flex;
  align-items: center;
  justify-content: center;
}

.voice-message-btn {
  width: 100% !important;
  height: 40px !important;
  border-radius: 20px !important;
  font-size: 14px !important;
  transition: all 0.2s ease !important;
}

.voice-message-btn.n-button--primary {
  animation: voice-message-pulse 1.5s ease-in-out infinite;
}

.recording-indicator {
  display: flex;
  align-items: center;
  gap: 8px;
}

.message-input {
  border: none !important;
  box-shadow: none !important;
  background: transparent !important;
  width: 100%;
}

.message-input :deep(.n-input__input-el) {
  font-size: 16px !important;
  line-height: 1.5 !important;
  padding: 8px 0 !important;
  min-height: 24px !important;
}

.message-input :deep(.n-input__textarea-el) {
  font-size: 16px !important;
  line-height: 1.5 !important;
  padding: 8px 0 !important;
  min-height: 24px !important;
  resize: none !important;
}

.send-btn {
  flex-shrink: 0;
  width: 40px !important;
  height: 40px !important;
  transition: all 0.2s ease;
}

.send-btn:not(:disabled):hover {
  transform: scale(1.05);
}

.send-btn:not(:disabled):active {
  transform: scale(0.95);
}


/* ç§»åŠ¨ç«¯é€‚é… */
@media (max-width: 768px) {
  .chat-input-bar {
    max-width: 100%;
    margin: 0;
  }
  
  .input-container {
    padding: 12px 16px;
    gap: 12px;
    border-radius: 20px;
    min-height: 48px;
  }
  
  .voice-btn,
  .send-btn {
    width: 36px !important;
    height: 36px !important;
  }
  
  .voice-wave-container {
    min-height: 36px;
    margin: 0 2px;
    padding: 6px 12px;
  }
  
  .text-input-container {
    margin: 0 2px;
  }
  
  .message-input :deep(.n-input__textarea-el) {
    font-size: 16px !important;
    padding: 6px 0 !important;
  }
}

/* å½•éŸ³çŠ¶æ€åŠ¨ç”» */
.voice-to-text-btn.n-button--primary {
  animation: recording-pulse 1.5s ease-in-out infinite;
}


@keyframes recording-pulse {
  0% {
    box-shadow: 0 0 0 0 rgba(22, 119, 255, 0.4);
  }
  70% {
    box-shadow: 0 0 0 10px rgba(22, 119, 255, 0);
  }
  100% {
    box-shadow: 0 0 0 0 rgba(22, 119, 255, 0);
  }
}

@keyframes microphone-pulse {
  0% {
    box-shadow: 0 0 0 0 rgba(22, 119, 255, 0.4);
  }
  70% {
    box-shadow: 0 0 0 10px rgba(22, 119, 255, 0);
  }
  100% {
    box-shadow: 0 0 0 0 rgba(22, 119, 255, 0);
  }
}

@keyframes pulse-dot {
  0%, 100% {
    opacity: 1;
    transform: scale(1);
  }
  50% {
    opacity: 0.5;
    transform: scale(1.2);
  }
}

@keyframes voice-message-pulse {
  0% {
    box-shadow: 0 0 0 0 rgba(22, 119, 255, 0.4);
  }
  70% {
    box-shadow: 0 0 0 10px rgba(22, 119, 255, 0);
  }
  100% {
    box-shadow: 0 0 0 0 rgba(22, 119, 255, 0);
  }
}

/* RAGå¼€å…³æ ·å¼ */
.rag-toggle-container {
  position: absolute;
  top: 10px;
  left: 10px;
  display: flex;
  align-items: center;
  gap: 8px;
  font-size: 12px;
  color: #666;
  z-index: 10;
  background: rgba(255, 255, 255, 0.9);
  padding: 4px 8px;
  border-radius: 4px;
}

</style>

