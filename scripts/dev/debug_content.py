#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•é¡µé¢å†…å®¹è„šæœ¬
æ£€æŸ¥é¡µé¢çš„åŸå§‹HTMLå†…å®¹
"""

import requests
from bs4 import BeautifulSoup

def debug_page_content():
    """è°ƒè¯•é¡µé¢å†…å®¹"""
    url = "https://harrypotter.fandom.com/zh/wiki/%E5%88%86%E9%99%A2%E5%B8%BD"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        
        # ä¿å­˜åŸå§‹HTMLç”¨äºè°ƒè¯•
        with open('debug_page.html', 'w', encoding='utf-8') as f:
            f.write(response.text)
        
        print(f"âœ… åŸå§‹HTMLå·²ä¿å­˜åˆ° debug_page.html")
        print(f"ğŸ“„ å†…å®¹é•¿åº¦: {len(response.text)} å­—ç¬¦")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æŸäº›å…³é”®è¯
        content = response.text.lower()
        keywords = ['åˆ†é™¢å¸½', 'sorting hat', 'éœæ ¼æ²ƒèŒ¨', 'hogwarts', 'javascript', 'loading']
        
        print("\nğŸ” å…³é”®è¯æ£€æŸ¥:")
        for keyword in keywords:
            if keyword in content:
                print(f"  âœ… æ‰¾åˆ°: {keyword}")
            else:
                print(f"  âŒ æœªæ‰¾åˆ°: {keyword}")
        
        # æ£€æŸ¥é¡µé¢ç»“æ„
        soup = BeautifulSoup(response.text, 'html.parser')
        
        print(f"\nğŸ“Š é¡µé¢ç»“æ„:")
        print(f"  æ ‡é¢˜æ ‡ç­¾æ•°é‡: {len(soup.find_all('title'))}")
        print(f"  H1æ ‡ç­¾æ•°é‡: {len(soup.find_all('h1'))}")
        print(f"  æ®µè½æ ‡ç­¾æ•°é‡: {len(soup.find_all('p'))}")
        print(f"  Divæ ‡ç­¾æ•°é‡: {len(soup.find_all('div'))}")
        
        # æŸ¥æ‰¾æ‰€æœ‰H1æ ‡ç­¾çš„å†…å®¹
        h1_tags = soup.find_all('h1')
        print(f"\nğŸ“ H1æ ‡ç­¾å†…å®¹:")
        for i, h1 in enumerate(h1_tags):
            print(f"  H1-{i+1}: {h1.get_text().strip()}")
        
        # æŸ¥æ‰¾æ‰€æœ‰æœ‰classå±æ€§çš„div
        divs = soup.find_all('div', class_=True)
        print(f"\nğŸ·ï¸  å‰10ä¸ªdivçš„classå±æ€§:")
        for i, div in enumerate(divs[:10]):
            classes = ' '.join(div.get('class', []))
            print(f"  Div-{i+1}: {classes}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å®šçš„å†…å®¹åŠ è½½æŒ‡ç¤ºå™¨
        loading_indicators = [
            'loading',
            'spinner',
            'skeleton',
            'placeholder',
            'lazy'
        ]
        
        print(f"\nâ³ åŠ è½½æŒ‡ç¤ºå™¨æ£€æŸ¥:")
        for indicator in loading_indicators:
            elements = soup.find_all(True, {'class': lambda x: x and indicator in ' '.join(x)})
            if elements:
                print(f"  âš ï¸  æ‰¾åˆ° {indicator} ç›¸å…³å…ƒç´ : {len(elements)} ä¸ª")
        
        return True
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ” é¡µé¢å†…å®¹è°ƒè¯•å™¨")
    print("=" * 40)
    debug_page_content()
