#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•é€‰æ‹©å™¨è„šæœ¬
æµ‹è¯•å„ç§é€‰æ‹©å™¨çš„å·¥ä½œæƒ…å†µ
"""

import requests
from bs4 import BeautifulSoup

def debug_selectors():
    """è°ƒè¯•é€‰æ‹©å™¨"""
    url = "https://harrypotter.fandom.com/zh/wiki/%E5%88%86%E9%99%A2%E5%B8%BD"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    response = requests.get(url, headers=headers, timeout=10)
    response.encoding = 'utf-8'
    
    soup = BeautifulSoup(response.text, 'html.parser')
    
    print("ğŸ” é€‰æ‹©å™¨è°ƒè¯•")
    print("=" * 40)
    
    # æµ‹è¯•å„ç§é€‰æ‹©å™¨æ–¹å¼
    selectors = [
        # ä½¿ç”¨ select_one (CSSé€‰æ‹©å™¨)
        ('soup.select_one("div[id=\\"mw-content-text\\"]")', lambda: soup.select_one('div[id="mw-content-text"]')),
        ('soup.select_one("div#mw-content-text")', lambda: soup.select_one('div#mw-content-text')),
        ('soup.select_one("div.main-container")', lambda: soup.select_one('div.main-container')),
        
        # ä½¿ç”¨ find (BeautifulSoupæ–¹å¼)
        ('soup.find("div", id="mw-content-text")', lambda: soup.find('div', id='mw-content-text')),
        ('soup.find("div", {"id": "mw-content-text"})', lambda: soup.find('div', {'id': 'mw-content-text'})),
        ('soup.find("div", class_="main-container")', lambda: soup.find('div', class_='main-container')),
        
        # ä½¿ç”¨ find_all ç„¶åå–ç¬¬ä¸€ä¸ª
        ('soup.find_all("div", id="mw-content-text")[0]', lambda: soup.find_all('div', id='mw-content-text')[0] if soup.find_all('div', id='mw-content-text') else None),
    ]
    
    for desc, selector_func in selectors:
        try:
            result = selector_func()
            if result:
                paragraphs = result.find_all('p')
                valid_content = any('åˆ†é™¢å¸½' in p.get_text() for p in paragraphs[:10])
                print(f"âœ… {desc}: æ‰¾åˆ°å…ƒç´ ï¼Œ{len(paragraphs)}ä¸ªæ®µè½ï¼Œå†…å®¹æœ‰æ•ˆ: {valid_content}")
                
                if valid_content:
                    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç›¸å…³æ®µè½
                    for p in paragraphs:
                        text = p.get_text().strip()
                        if 'åˆ†é™¢å¸½' in text and len(text) > 50:
                            print(f"   ğŸ“„ æ ·ä¾‹å†…å®¹: {text[:100]}...")
                            break
            else:
                print(f"âŒ {desc}: æœªæ‰¾åˆ°å…ƒç´ ")
        except Exception as e:
            print(f"âŒ {desc}: å¼‚å¸¸ - {e}")
    
    # æŸ¥æ‰¾æ‰€æœ‰æœ‰idçš„div
    print(f"\nğŸ·ï¸  é¡µé¢ä¸­æ‰€æœ‰æœ‰IDçš„div:")
    divs_with_id = soup.find_all('div', id=True)
    for div in divs_with_id[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
        div_id = div.get('id')
        print(f"   ID: '{div_id}'")

if __name__ == "__main__":
    debug_selectors()
