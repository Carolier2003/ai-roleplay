#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è§„æ¨¡çˆ¬è™«æµ‹è¯•
æµ‹è¯•å®Œæ•´çš„çˆ¬å– -> å¤„ç† -> å¯¼å…¥æµç¨‹
"""

import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(__file__))

from harry_potter_wiki_crawler import HarryPotterWikiCrawler
from data_processor import HarryPotterDataProcessor
import json
import time

class SmallCrawlTest:
    """å°è§„æ¨¡çˆ¬è™«æµ‹è¯•"""
    
    def __init__(self):
        self.output_dir = "test_data"
        os.makedirs(self.output_dir, exist_ok=True)
    
    def run_test_crawl(self):
        """è¿è¡Œæµ‹è¯•çˆ¬å–"""
        print("ğŸ§ª å¼€å§‹å°è§„æ¨¡çˆ¬è™«æµ‹è¯•...")
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        crawler = HarryPotterWikiCrawler()
        
        # ä¿®æ”¹è¾“å‡ºç›®å½•
        crawler.output_dir = f"{self.output_dir}/harry_potter_wiki"
        
        # è®¾ç½®æµ‹è¯•é…ç½® (åªçˆ¬å–3ä¸ªé¡µé¢ï¼Œä½¿ç”¨URLç¼–ç )
        test_config = {
            "test_pages": {
                "urls": [
                    "/wiki/%E5%88%86%E9%99%A2%E5%B8%BD",              # åˆ†é™¢å¸½
                    "/wiki/%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9",  # å“ˆåˆ©Â·æ³¢ç‰¹  
                    "/wiki/%E9%9C%8D%E6%A0%BC%E6%B2%83%E8%8C%A8%E9%AD%94%E6%B3%95%E5%AD%A6%E6%A0%A1"  # éœæ ¼æ²ƒèŒ¨
                ],
                "importance": 9,
                "category": "TEST_DATA"
            }
        }
        
        # æ›¿æ¢çˆ¬å–é…ç½®
        crawler.crawl_config = test_config
        
        try:
            crawler.run()
            print("âœ… æµ‹è¯•çˆ¬å–å®Œæˆ")
            return True
        except Exception as e:
            print(f"âŒ æµ‹è¯•çˆ¬å–å¤±è´¥: {e}")
            return False
    
    def run_test_processing(self):
        """è¿è¡Œæµ‹è¯•æ•°æ®å¤„ç†"""
        print("\nğŸ“š å¼€å§‹æµ‹è¯•æ•°æ®å¤„ç†...")
        
        try:
            processor = HarryPotterDataProcessor(f"{self.output_dir}/harry_potter_wiki")
            processed_data = processor.process_data()
            
            if not processed_data:
                print("âŒ æ²¡æœ‰å¤„ç†åˆ°æ•°æ®")
                return False
            
            # ä¿å­˜å¤„ç†åçš„æ•°æ®
            output_file = processor.save_processed_data(
                processed_data, 
                f"{self.output_dir}/test_knowledge.json"
            )
            
            print(f"âœ… æµ‹è¯•å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(processed_data)} ä¸ªçŸ¥è¯†æ¡ç›®")
            return True
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤„ç†å¤±è´¥: {e}")
            return False
    
    def show_processed_data_preview(self):
        """æ˜¾ç¤ºå¤„ç†åæ•°æ®çš„é¢„è§ˆ"""
        print("\nğŸ“‹ å¤„ç†åæ•°æ®é¢„è§ˆ:")
        
        try:
            with open(f"{self.output_dir}/test_knowledge.json", 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            for i, item in enumerate(data[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"\nğŸ“– çŸ¥è¯†æ¡ç›® {i+1}:")
                print(f"   æ ‡é¢˜: {item['title']}")
                print(f"   ç±»å‹: {item['knowledgeType']}")
                print(f"   é‡è¦æ€§: {item['importance']}")
                print(f"   å†…å®¹é¢„è§ˆ: {item['content'][:100]}...")
                print(f"   æ ‡ç­¾: {', '.join(item['tags'][:3])}")
            
            if len(data) > 3:
                print(f"\n... è¿˜æœ‰ {len(data) - 3} ä¸ªçŸ¥è¯†æ¡ç›®")
        
        except Exception as e:
            print(f"âŒ é¢„è§ˆå¤±è´¥: {e}")
    
    def cleanup(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        print(f"\nğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®: {self.output_dir}")
        import shutil
        if os.path.exists(self.output_dir):
            shutil.rmtree(self.output_dir)
            print("âœ… æ¸…ç†å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª å“ˆåˆ©Â·æ³¢ç‰¹ç»´åŸºå°è§„æ¨¡æµ‹è¯•")
    print("=" * 50)
    
    test = SmallCrawlTest()
    
    try:
        # æ­¥éª¤1: æµ‹è¯•çˆ¬å–
        if not test.run_test_crawl():
            return
        
        # æ­¥éª¤2: æµ‹è¯•å¤„ç†
        if not test.run_test_processing():
            return
        
        # æ­¥éª¤3: æ˜¾ç¤ºé¢„è§ˆ
        test.show_processed_data_preview()
        
        print("\nğŸ‰ å°è§„æ¨¡æµ‹è¯•å®Œæˆï¼")
        print("âœ… çˆ¬å–ã€å¤„ç†æµç¨‹éƒ½æ­£å¸¸å·¥ä½œ")
        print("ğŸ‘‰ ç°åœ¨å¯ä»¥è¿è¡Œå®Œæ•´çˆ¬è™«: ./run_crawler.sh all")
        
        # è¯¢é—®æ˜¯å¦æ¸…ç†
        response = input("\nğŸ—‘ï¸  æ˜¯å¦æ¸…ç†æµ‹è¯•æ•°æ®ï¼Ÿ(y/N): ").strip().lower()
        if response == 'y':
            test.cleanup()
        else:
            print(f"ğŸ“ æµ‹è¯•æ•°æ®ä¿ç•™åœ¨: {test.output_dir}")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ä¸­æ–­")
        test.cleanup()
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
